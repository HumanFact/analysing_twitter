{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#Module to handle regular expressions\n",
    "import re\n",
    "#Library for emoji\n",
    "import emoji\n",
    "#Import pandas and numpy to handle data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import libraries for accessing the database\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from postgres_credentials import *\n",
    "\n",
    "#import libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Import nltk to check english lexicon\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#import libraries for tokenization and ML\n",
    "import json;\n",
    "import keras;\n",
    "import keras.preprocessing.text as kpt;\n",
    "from keras.preprocessing.text import Tokenizer;\n",
    "\n",
    "\n",
    "#Import all libraries for creating a deep neural network\n",
    "#Sequential is the standard type of neural network with stackable layers\n",
    "from keras.models import Sequential;\n",
    "#Dense: Standard layers with every node connected, dropout: avoids overfitting\n",
    "from keras.layers import Dense, Dropout, Activation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Querying the database\n",
    "def query_database(tabletweets):\n",
    "    engine = create_engine(\"postgresql+psycopg2://%s:%s@%s:%d/%s\" %(usertwitter, passwordtwitter, hosttwitter, porttwitter, dbnametwitter))\n",
    "    table = pd.read_sql_query('select * from %s' %tabletweets,con=engine, index_col='id')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess text in tweets by removing links, @UserNames, blank spaces, etc.\n",
    "def preprocessing_text(table):\n",
    "    #put everythin in lowercase\n",
    "    table['tweet'] = table['tweet'].str.lower()\n",
    "    #Replace rt indicating that was a retweet\n",
    "    table['tweet'] = table['tweet'].str.replace('rt', '')\n",
    "    #Replace occurences of mentioning @UserNames\n",
    "    table['tweet'] = table['tweet'].replace(r'@\\w+', '', regex=True)\n",
    "    #Replace links contained in the tweet\n",
    "    table['tweet'] = table['tweet'].replace(r'http\\S+', '', regex=True)\n",
    "    table['tweet'] = table['tweet'].replace(r'www.[^ ]+', '', regex=True)\n",
    "    #remove numbers\n",
    "    table['tweet'] = table['tweet'].replace(r'[0-9]+', '', regex=True)\n",
    "    #replace special characters and puntuation marks\n",
    "    table['tweet'] = table['tweet'].replace(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]', '', regex=True)\n",
    "    return table    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_dict(word):\n",
    "    if wordnet.synsets(word):\n",
    "        #if the word is in the dictionary, we'll return True\n",
    "        return True\n",
    "\n",
    "def replace_elongated_word(word):\n",
    "    regex = r'(\\w*)(\\w+)\\2(\\w*)'\n",
    "    repl = r'\\1\\2\\3'    \n",
    "    if in_dict(word):\n",
    "        return word\n",
    "    new_word = re.sub(regex, repl, word)\n",
    "    if new_word != word:\n",
    "        return replace_elongated_word(new_word)\n",
    "    else:\n",
    "        return new_word\n",
    "\n",
    "def detect_elongated_words(row):\n",
    "    regexrep = r'(\\w*)(\\w+)(\\2)(\\w*)'\n",
    "    words = [''.join(i) for i in re.findall(regexrep, row)]\n",
    "    for word in words:\n",
    "        if not in_dict(word):\n",
    "            row = re.sub(word, replace_elongated_word(word), row)\n",
    "    return row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_words(table):\n",
    "    filler_words = stopwords.words('english')\n",
    "    table['tweet'] = df['tweet'].str.lower()\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (filler_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_table(table):\n",
    "    tweet_table = preprocessing_text(tweet_table)\n",
    "    tweet_table['tweet'] = tweet_table['tweet'].apply(lambda x: detect_elongated_words(x))\n",
    "    tweet_table = filling_words(table)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the data: Tokenization\n",
    "def tokenization_tweets(table):\n",
    "    tokenization = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True, split=' ')\n",
    "    tokenization.fit_on_texts(table['tweet'])\n",
    "    return tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step2: Create a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "def train():\n",
    "    model_nn = Sequential()\n",
    "    model.add(Dense(512, input_shape=(max_words,), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['acuracy'])\n",
    "    model.fit(X_train, Y_train,\n",
    "             batch_size=32,\n",
    "             epochs=5,\n",
    "             verbose=1,\n",
    "             validation_split=0.1,\n",
    "             shuffle=True)\n",
    "    pred=model.predict(input_data)\n",
    "    labels[np.argmax(pred)], pred[0][np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tabletweets = 'tweets_avengers'\n",
    "    tweet_table = query_database(tabletweets)\n",
    "    tweet_table = cleaning(tweet_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>user_id</th>\n",
       "      <th>retweetcount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-19 01:15:31</td>\n",
       "      <td>video lee sugeun youtube channel  subscriber...</td>\n",
       "      <td>271496866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-19 01:15:35</td>\n",
       "      <td>avengers  trailer as told by spongebob and f...</td>\n",
       "      <td>2885234679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-19 01:15:42</td>\n",
       "      <td>ok so i just watched avengers infinity war for...</td>\n",
       "      <td>14365631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-19 01:15:42</td>\n",
       "      <td>always good to know  has your back</td>\n",
       "      <td>797228831031508992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-12-19 01:15:44</td>\n",
       "      <td>making new oreo products used to be so easy ...</td>\n",
       "      <td>1037117267396501504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                              tweet  \\\n",
       "id                                                                          \n",
       "1  2018-12-19 01:15:31    video lee sugeun youtube channel  subscriber...   \n",
       "2  2018-12-19 01:15:35    avengers  trailer as told by spongebob and f...   \n",
       "3  2018-12-19 01:15:42  ok so i just watched avengers infinity war for...   \n",
       "4  2018-12-19 01:15:42                always good to know  has your back    \n",
       "5  2018-12-19 01:15:44    making new oreo products used to be so easy ...   \n",
       "\n",
       "                user_id  retweetcount  \n",
       "id                                     \n",
       "1             271496866             0  \n",
       "2            2885234679             0  \n",
       "3              14365631             0  \n",
       "4    797228831031508992             0  \n",
       "5   1037117267396501504             0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
